{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from collections import Counter, OrderedDict\n",
    "import operator\n",
    "import itertools\n",
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the two datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"C:/Users/r.parisi.cons/Desktop/Materiale didattico\")\n",
    "dfalpha = pd.read_csv(\"tweets.csv\",  error_bad_lines=False, sep=\";\")\n",
    "dfusers = pd.read_csv(\"users.csv\",  error_bad_lines=False, sep=\";\")\n",
    "dfusers[' user id'] = dfusers['user id']\n",
    "dfusers.drop('user id', inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funzioni:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "* delete_retweet(df) : takes as input a dataframe and drop from it all the row where the column 1 (messages' column) starts with \"RT\" and return a new df \n",
    "\n",
    "        \n",
    "* turn_into_dictionary(df) : takes in input a dataframe and turn it into a dictionary but modifying the messages' column by splittig the text inside (without doing anything else like stemming, tokenization ecc..). Come output da il dizionario creato. \n",
    " \n",
    " \n",
    "* frequencies(docs) : taking as input a dictionary of messagges this function transforme it in another dictionary which has inside all the user (KEY) with the hashtags that they used in their message (considering either tweets and retweets).\n",
    " \n",
    " \n",
    "* inverted_index (user_hashtags) : it takes as input the dictionary created in frequencies and create an inverted index (Key: Hashtag; Value : list of Users) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_retweet (df):\n",
    "    to_drop = []\n",
    "    for i in range(len(df)):\n",
    "        if df.iloc[i][1].startswith(\"RT\"): \n",
    "            to_drop.append(i)\n",
    "    df.drop(to_drop, inplace = True, axis = 0)\n",
    "    df.reset_index(drop = True, inplace = True)\n",
    "    return (df)\n",
    "        \n",
    "#funzione che trasforma il dataframe in una dictionary con chiave l'id del tweet e come valore ha a sua volta una dictionary che\n",
    "# prende come chiave l'user id e come valore il messaggio del tweet in questione (splittando le varie parole contenute, in modo \n",
    "# da facilitare le operazioni successive, in cui vogliamo estrapolare solo gli hashtags)\n",
    "def turn_into_dictionary (df):     \n",
    "    d = df.to_dict(\"index\")\n",
    "    docs = {}\n",
    "    for k1 in d.keys():\n",
    "        docs[k1] = {d[k1][\" user id\"] : d[k1][\"message\"].split(\" \")}\n",
    "    return docs    \n",
    "\n",
    "#in questa funzione prendiamo in input l'output della funzione turn_into_dictionary e restituiamo una dictionary in cui contiamo\n",
    "#hashtags usati da ogni utente e in più una lista degli hashtag usati in generale\n",
    "\n",
    "def frequencies (docs):\n",
    "    hashtags_list = []\n",
    "    user_hashtags = dict()\n",
    "    for i in range(len(docs)):\n",
    "        user = list(docs[i].keys())[0]\n",
    "        line = docs[i][user]\n",
    "        hashtags = [word for word in line if word.startswith(\"#\")]\n",
    "        if len(hashtags)!=0: #alcuni user twittano senza usare gli hashtag, è inutile portarseli dietro\n",
    "            hashtags_list = hashtags_list+ hashtags\n",
    "            if user in user_hashtags.keys():\n",
    "                #user_hashtags[user].update(hashtags)\n",
    "                user_hashtags[user] = list(set(user_hashtags[user] + hashtags))\n",
    "            else:\n",
    "                #user_hashtags[user] = Counter(hashtags)\n",
    "                user_hashtags[user] = hashtags\n",
    "    hashtags_count = dict(Counter(hashtags_list))\n",
    "    return (user_hashtags, hashtags_count)\n",
    "\n",
    "#inverted index that contains as key the hashtag and as value the list of the user that used it\n",
    "def inverted_index (user_hashtags, hashtags_count):\n",
    "    inv_idx = {}\n",
    "    hashtags = list(hashtag_freq.keys())\n",
    "    for key in hashtags:\n",
    "        inv_idx [key] = [user for user in user_hashtags.keys() if key in user_hashtags[user]]\n",
    "    return inv_idx\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying all the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_hasht, hashtag_freq = frequencies (turn_into_dictionary(dfalpha))\n",
    "#i created also hashtag_freq considering that could be usefull to know how many times each users used that hashtag\n",
    "most_used = sorted(hashtag_freq.items(), key=operator.itemgetter(1), reverse = True)[:3]\n",
    "inv_idx = inverted_index(user_hasht)\n",
    "user_to_check = list(itertools.chain.from_iterable([inv_idx[i[0]] for i in most_used]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In user_msg we have the users' id with the message and we print it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_msg = [(dfalpha.iloc[i][\" user id\"],dfalpha.iloc[i][\"message\"]) for i in range(len(dfalpha)) if dfalpha.iloc[i][\" user id\"] in user_to_check]\n",
    "#print(*chain(*user_msg), sep = \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We merge the two dataset since i want to have all the message (excluding the RETWEET) of the users ordered by the number of followers of each users (descendent). We save it in a file without the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdf = dfalpha[[\" user id\", \"message\"]].merge(dfusers[[\" user id\", \" followers\"]], on = \" user id\")\n",
    "df_withoutRT = delete_retweet(newdf).sort_values(by= \" followers\", ascending = False)\n",
    "#df_withoutRT.reset_index(drop = True, inplace = True)\n",
    "df_withoutRT.to_csv(\"FinalAlpha.csv\", sep = \";\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
